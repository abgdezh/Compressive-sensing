\documentclass{article}
\synctex=1
\usepackage[utf8x]{inputenc}
\usepackage[russian]{babel}
\usepackage [T2A] {fontenc}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage[left=20mm, top=10mm, right=10mm, bottom=10mm, nohead, nofoot]{geometry}

\begin{document}
\author{Михаил Богомолов}
\title{План проекта}
%\date{}
\maketitle

Я собираюсь проверить оценки из статьи \textit{M. Rani et al.: Systematic Review of CS: Concepts, Implementations and Applications} на количество необходимых измерений для точного восстановления исходных разреженных данных. В качестве данных для сигнала я буду использовать реальные фотографии и музыкальные аудиозаписи в базисе дискретного преобразования Фурье. Я провёл некоторые эксперименты с аудиозаписями и решил, что они являются достаточно разреженными в Фурье-базисе. Я считал преобразование Фурье на небольшом фрагменте исходных данных (порядка $0.05$ секунды) и отбрасывал все компоненты, кроме нескольких (от $1$ до $10$) максимальных, а затем считал обратное преобразование и оценивал на слух, насколько исходная аудиозапись распознаваема. Я пришёл к мысли, что в действительности требуется значительно меньшее (в сотни раз) количество информации, чтобы закодировать реальные аудиозаписи в относительно приемлемом для восприятия формате, а значит, compressive sensing может быть применимо к этой задаче, поскольку исходные данные сильно разрежены. 

С изображениями я пока не пробовал проводить эксперименты, но я видел в нескольких статьях подобные результаты, и думаю, что к ним это тоже применимо. 

Так вот, я собираюсь оценить размер measurement vector'а, который необходим для точного восстановления данных.

Проверяемые оценки:
\begin{enumerate}
	\item $ m = O(k\log{n/k})$ для матрицы из независимых случайных величин, имеющих распределение Гаусса или Бернулли
	\item $ m = O(k\log{W/k})$ для произведения диагональной матрицы из $\pm 1$ и матрицы из $m$ единичных блоков размера $1 \times n/m$, расположенных вдоль диагонали
\end{enumerate}

Кроме того, я хочу по-разному восстанавливать $x$.

Способы восстановления $x$:
\begin{enumerate}
	\item Минимизация $L_1$ нормы
	\item Минимизация $L_p$ нормы, где $0 < p < 1$
	\item Можно сделать предположение, что входной сигнал принадлежит какому-то известному вероятностному распределению, а затем максимизировать оценку апостериорного максимума (Байесовский подход).
\end{enumerate}


\end{document}
